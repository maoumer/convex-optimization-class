# Automatic Differentiation demos

- **Python**: see [../AutomaticDifferentiation.ipynb](../AutomaticDifferentiation.ipynb)
- **Julia**: see [ForwardDiff.jl/](ForwardDiff.jl/) package. Julia has a rich ecosystem of autodiff tools, which are constantly evolving, so we have not attempted to be up-to-date
  - A [discourse post](https://discourse.julialang.org/t/state-of-automatic-differentiation-in-julia/43083) from about 2020 (and see followup comments) lists about 20 packages: FowardDiff
ForwardDiff2, Nabla, Tracker, Yota, Zygote, ReverseDiff, AutoGrad, NiLang, ModelingToolkit, XGrad, Calculus, FiniteDifferences, FiniteDiff, TaylorSeries, DualNumbers, HyperDualNumbers, Knet, Capstan, Flux, ...
- **Matlab**: historically, Matlab hasn't had a rich autodiff community.  When this class first ran in 2016, we used ADiGator (see [ADiGator_demo/](ADiGator_demo/)
  - As of version R2021a, with the Deep Learning Toolbox, there is now much better native support. See, e.g., [mathworks.com/help/deeplearning/ug/include-automatic-differentiation.html](https://www.mathworks.com/help/deeplearning/ug/include-automatic-differentiation.html).
